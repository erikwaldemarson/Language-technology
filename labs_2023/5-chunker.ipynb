{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25f012936b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train.txt'\n",
    "test_file = 'test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n",
    "def cosine(v, w):\n",
    "    return np.dot(v, w) / (np.linalg.norm(v)*np.linalg.norm(w))\n",
    "    \n",
    "\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    sorted_items = sorted(embeddings.items(), key=lambda x: cosine(x[1], embeddings[target_word]), reverse=True)[:10]\n",
    "    return [key[0] for key in sorted_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for index1, sentence in enumerate(corpus_dict):\n",
    "        words = []\n",
    "        chunks = []\n",
    "        for index2, word in enumerate(corpus_dict[index1]):\n",
    "            x = corpus_dict[index1][index2][key_x]\n",
    "            y = corpus_dict[index1][index2][key_y]\n",
    "\n",
    "            if tolower is True:\n",
    "                x = x.lower()\n",
    "\n",
    "            words.append(x)\n",
    "            chunks.append(y)\n",
    "\n",
    "        X.append(words)\n",
    "        Y.append(chunks)  \n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words = sorted(list(set([word for sentence in X_train_symbs for word in sentence])))\n",
    "chunks = sorted(list(set([chunk for sentence in Y_train_symbs for chunk in sentence])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = embedded_words + words\n",
    "vocabulary_words = sorted(list(set(vocabulary_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = {}\n",
    "word2idx = {}\n",
    "\n",
    "for idx, word in enumerate(vocabulary_words):\n",
    "    idx2word[idx + 2] = word\n",
    "    word2idx[word] = idx + 2\n",
    "\n",
    "\n",
    "idx2chunk = {}\n",
    "chunk2idx = {}\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    idx2chunk[idx + 1] = chunk\n",
    "    chunk2idx[chunk] = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix2 = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "\n",
    "#print(len(words)) #CoNLL\n",
    "\n",
    "#print(len(embedded_words)) # glove\n",
    "\n",
    "\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding_matrix[word2idx[word], :] = embeddings_dict[word] #replace row in matrix\n",
    "    else:\n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'embedding_matrix' (ndarray)\n",
      "Stored 'out_of_embeddings' (list)\n"
     ]
    }
   ],
   "source": [
    "%store embedding_matrix\n",
    "%store out_of_embeddings\n",
    "\n",
    "#%store -r embedding_matrix\n",
    "#%store -r out_of_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "\n",
    "    for word in x:\n",
    "        temp_x.append(word2idx[word])\n",
    "    for chunk in y:\n",
    "        temp_y.append(chunk2idx[chunk])\n",
    "    \n",
    "    X_train_idx.append(temp_x)\n",
    "    Y_train_idx.append(temp_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dim = torch.tensor(embedding_matrix).size()[-1] \n",
    "        self.embeddings = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix), \n",
    "                                                       freeze= True, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "        #LSTM\n",
    "        #self.lstm = nn.LSTM(embedding_dim, lstm_units, num_layers=1, dropout=DROPOUT, batch_first=True, bidirectional=bidi_lstm)\n",
    "\n",
    "        #RNN\n",
    "        self.rnn = nn.RNN(embedding_dim, lstm_units, num_layers=1, dropout=DROPOUT, batch_first=True, bidirectional=bidi_lstm)\n",
    "\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            # twice the units if bidirectional \n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        embeds = self.dropout(embeds)\n",
    "        \n",
    "        #LSTM\n",
    "        #lstm_out, _ = self.lstm(embeds)\n",
    "        #lstm_out = F.relu(lstm_out)\n",
    "        #lstm_out = self.dropout(lstm_out)\n",
    "        #logits = self.fc(lstm_out)\n",
    "\n",
    "        #RNN\n",
    "        rnn_out, _ = self.rnn(embeds)\n",
    "        rnn_out = F.relu(rnn_out)\n",
    "        rnn_out = self.dropout(rnn_out)\n",
    "        logits = self.fc(rnn_out)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erik\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (rnn): RNN(100, 128, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=128, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)    # cross entropy loss\n",
    "optimizer = torch.optim.RMSprop(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (rnn): RNN(100, 128, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=128, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:07<00:00, 39.50it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 40.72it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.05it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.24it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.10it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.34it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.29it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.35it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 40.94it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.11it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.14it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.10it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.08it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.04it/s]\n",
      "100%|██████████| 280/280 [00:06<00:00, 41.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'united', 'states', 'might', 'collapsez', '.']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = []\n",
    "for word in sentence:\n",
    "    if word in word2idx:\n",
    "        sentence_word_idxs.append(word2idx[word])\n",
    "    else: \n",
    "        sentence_word_idxs.append(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sentence_word_idxs = torch.tensor(sentence_word_idxs)\n",
    "sent_chunk_predictions = model1(sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.6443e-13, 4.9462e-05, 2.1928e-05, 2.5892e-07, 4.8503e-07, 3.9024e-07,\n",
       "        9.9910e-01, 5.0922e-04, 1.5719e-07, 8.1192e-06, 2.6721e-19, 1.1997e-06,\n",
       "        8.2094e-07, 1.2883e-07, 3.3768e-08, 4.3801e-09, 1.6136e-05, 1.4010e-06,\n",
       "        5.1134e-11, 3.8109e-09, 8.6345e-12, 2.5094e-07, 2.9131e-04],\n",
       "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11,  6, 22])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: B-NP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    temp_x = []\n",
    "\n",
    "    for word in x:\n",
    "        if word in word2idx:\n",
    "            temp_x.append(word2idx[word])\n",
    "        else: \n",
    "            temp_x.append(1)\n",
    "\n",
    "    X_test_idx.append(temp_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-16.8688,  -2.8466,  -1.5987,  ..., -10.5088,  -4.4460,   1.4444],\n",
      "        [-25.1977,  -3.3834,  -3.1474,  ..., -15.6164,  -0.1873,  -1.5659],\n",
      "        [-21.6857,  -3.4769,  -2.9123,  ..., -19.2184,  -5.6739,  -1.4481],\n",
      "        ...,\n",
      "        [-20.2368,  -0.8085,  -1.5906,  ...,  -7.5256,  -4.7221,   3.5806],\n",
      "        [-19.0193,  -1.5763,   0.1213,  ...,  -7.7850,  -3.1966,   3.2651],\n",
      "        [-19.1613,  -0.9256,   0.7546,  ...,  -7.6413,  -3.9249,   3.7798]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'O'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7908645468150972"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
