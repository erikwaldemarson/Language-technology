{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17a9856f650>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train.txt'\n",
    "test_file = 'test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n",
    "def cosine(v, w):\n",
    "    return np.dot(v, w) / (np.linalg.norm(v)*np.linalg.norm(w))\n",
    "    \n",
    "\n",
    "def closest2(target_word, embeddings, count=10):\n",
    "    sorted_items = sorted(embeddings.items(), key=lambda x: cosine(x[1], embeddings[target_word]), reverse=True)[:10]\n",
    "    return [key[0] for key in sorted_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for index1, sentence in enumerate(corpus_dict):\n",
    "        words = []\n",
    "        chunks = []\n",
    "        for index2, word in enumerate(corpus_dict[index1]):\n",
    "            x = corpus_dict[index1][index2][key_x]\n",
    "            y = corpus_dict[index1][index2][key_y]\n",
    "\n",
    "            if tolower is True:\n",
    "                x = x.lower()\n",
    "\n",
    "            words.append(x)\n",
    "            chunks.append(y)\n",
    "\n",
    "        X.append(words)\n",
    "        Y.append(chunks)  \n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words = sorted(list(set([word for sentence in X_train_symbs for word in sentence])))\n",
    "chunks = sorted(list(set([chunk for sentence in Y_train_symbs for chunk in sentence])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = embedded_words + words\n",
    "vocabulary_words = sorted(list(set(vocabulary_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = {}\n",
    "word2idx = {}\n",
    "\n",
    "for idx, word in enumerate(vocabulary_words):\n",
    "    idx2word[idx + 2] = word\n",
    "    word2idx[word] = idx + 2\n",
    "\n",
    "\n",
    "idx2chunk = {}\n",
    "chunk2idx = {}\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    idx2chunk[idx + 1] = chunk\n",
    "    chunk2idx[chunk] = idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix2 = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "\n",
    "#print(len(words)) #CoNLL\n",
    "\n",
    "#print(len(embedded_words)) # glove\n",
    "\n",
    "\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding_matrix[word2idx[word], :] = embeddings_dict[word] #replace row in matrix\n",
    "    else:\n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'embedding_matrix' (ndarray)\n",
      "Stored 'out_of_embeddings' (list)\n"
     ]
    }
   ],
   "source": [
    "%store embedding_matrix\n",
    "%store out_of_embeddings\n",
    "\n",
    "#%store -r embedding_matrix\n",
    "#%store -r out_of_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "\n",
    "    for word in x:\n",
    "        temp_x.append(word2idx[word])\n",
    "    for chunk in y:\n",
    "        temp_y.append(chunk2idx[chunk])\n",
    "    \n",
    "    X_train_idx.append(temp_x)\n",
    "    Y_train_idx.append(temp_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_matrix_tensor = torch.tensor(embedding_matrix)\n",
    "\n",
    "        embedding_dim = embedding_matrix_tensor.size()[-1] \n",
    "        self.embeddings = nn.Embedding.from_pretrained(embedding_matrix_tensor, \n",
    "                                                       freeze= True, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, num_layers=1, dropout=DROPOUT, batch_first=True, bidirectional=bidi_lstm)\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            # twice the units if bidirectional \n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        embeds = self.dropout(embeds)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = F.relu(lstm_out)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)    # cross entropy loss\n",
    "optimizer = torch.optim.RMSprop(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:43<00:00,  6.51it/s]\n",
      "100%|██████████| 280/280 [00:40<00:00,  6.84it/s]\n",
      "100%|██████████| 280/280 [00:40<00:00,  6.88it/s]\n",
      "100%|██████████| 280/280 [00:41<00:00,  6.80it/s]\n",
      "100%|██████████| 280/280 [00:41<00:00,  6.80it/s]\n",
      "100%|██████████| 280/280 [00:41<00:00,  6.78it/s]\n",
      "100%|██████████| 280/280 [00:41<00:00,  6.77it/s]\n",
      "100%|██████████| 280/280 [00:41<00:00,  6.75it/s]\n",
      "100%|██████████| 280/280 [00:41<00:00,  6.77it/s]\n",
      "100%|██████████| 280/280 [00:41<00:00,  6.71it/s]\n",
      "100%|██████████| 280/280 [00:41<00:00,  6.79it/s]\n",
      "100%|██████████| 280/280 [00:41<00:00,  6.82it/s]\n",
      "100%|██████████| 280/280 [00:41<00:00,  6.82it/s]\n",
      "100%|██████████| 280/280 [00:40<00:00,  6.84it/s]\n",
      "100%|██████████| 280/280 [00:40<00:00,  6.83it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'united', 'states', 'might', 'collapsez', '.']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = []\n",
    "for word in sentence:\n",
    "    if word in word2idx:\n",
    "        sentence_word_idxs.append(word2idx[word])\n",
    "    else: \n",
    "        sentence_word_idxs.append(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sentence_word_idxs = torch.tensor(sentence_word_idxs)\n",
    "sent_chunk_predictions = model1(sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.6551e-10, 3.3151e-04, 1.3584e-03, 3.9265e-05, 2.4217e-05, 3.6701e-05,\n",
       "        9.7870e-01, 9.5354e-03, 8.2666e-05, 1.4589e-03, 2.4529e-12, 1.4920e-06,\n",
       "        1.8022e-05, 3.4065e-05, 9.3024e-05, 2.5524e-06, 9.2355e-04, 9.3187e-05,\n",
       "        2.9546e-07, 5.3733e-06, 5.1371e-07, 5.4388e-07, 7.2559e-03],\n",
       "       dtype=torch.float64, grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    temp_x = []\n",
    "\n",
    "    for word in x:\n",
    "        if word in word2idx:\n",
    "            temp_x.append(word2idx[word])\n",
    "        else: \n",
    "            temp_x.append(1)\n",
    "\n",
    "    X_test_idx.append(temp_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-16.7608,  -3.5441,  -2.9293,  ...,  -7.6690,  -5.2802,  -0.6826],\n",
      "        [-21.9437,  -8.3296,  -2.9644,  ..., -11.0469,  -3.8291,   2.2507],\n",
      "        [-20.5489,  -2.9962,  -1.1268,  ..., -12.8697,  -6.7515,   0.1390],\n",
      "        ...,\n",
      "        [ -8.3235,  -2.2002,  -2.8305,  ...,  -9.3879,  -3.5597,   3.7068],\n",
      "        [ -9.2760,  -3.3692,  -3.2553,  ..., -11.4507,  -5.1714,   3.9387],\n",
      "        [ -9.4115,  -2.6653,  -3.0327,  ..., -13.9654,  -5.6553,   4.7306]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.871637074306624"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
